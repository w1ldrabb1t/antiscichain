# What's on your mind today?

### Just start writing...

This is an idea for future work (I don't plan to address this right now...)

# Reducing the agent-principal problem by following (and exposing) the money
What if I enable research projects to be funded on my blockchain?
This way it would be possible to track, with full transparency, the money flows... who is funding what project.
The reason why this is important is because I want to expose research projects that are heavily biased towards finding "proof that it works" and that "no harm was found". By exposing who has 
"skin in the game" and is looking to gain from the system.

[Quoting Antifragile p.112](../antifragile-quotes.md) 
> "Iatrogenics is compounded by the 'agency problem' or 'principal-agent problem', which emerges when one party (the agent) has personal interests that are divorced from those of the one using his services (the principal)." #iatrogenisis

Funding via this blockchain wouldn't solve this problem but by exposing agents, it will reduce it's prevalence.

## First pass ideas on how to deal with this

There's several ways one could approach this.

### Anonymous wallets	
Anyone can fund a project without revealing any identity.
- (+) Maximum privacy and censorship resistance.
- (+) Encourages broad participation.
- (-) Easily used to hide conflicts of interest.
- (-) Impossible to detect biased funding.

### Pseudonymous wallets (e.g. ENS-like)
Funders use persistent on-chain IDs with history but no real-world identity.	
- (+) Allows reputation-building and pattern analysis.
- (+) More transparency than pure anon.
- (-) Can still hide real identity.
- (-) Sybil attacks possible (one entity making many wallets).

### IRL-authenticated funders
Funders must KYC or link their real-world identity.
- (+) Enables clear exposure of institutional or corporate bias.
- (+) Discourages self-dealing.
- (-) Higher friction to participate.
- (-) Reduces decentralization/privacy.
- (-) KYC data storage risks.

### Selective Transparency
Funders can choose between anonymity and verified identity but funding is labeled accordingly.	
- (+) Flexibility.
- (+) Can flag anonymous funders and require extra scrutiny for those projects.	
- (-) Bad actors will just choose anonymous.
- (-) May introduce credibility gaps between projects.

### Reputation-linked staking
Funders must stake tokens and risk loss if research is proven to be biased or fraudulent.
- (+) Strong incentives to fund rigorous research.
- (+) Encourages self-regulation.
- (-) Complex to enforce.
- (-) Needs reliable and manual "validation" system for research outcomes.
- (-) Breaks the fundamental rule of removing humans from the antifragile knowledge generation system (we can't nor should 
need trust them)


## Second pass - funding transparency together with ruin exposure influences the research credibility score
I'm dont want to block, censor nor require to trust the research authors by demanding funders to authenticate themselves.
Instead, *I want to make transparency (and the lack of it) a variable in the calculation of the research credibility score*.

When publishing resarch in the "Dangerous Ruin Zone" (High Scale + High Impact), I am purposing an incentive-aware weighting through the Decisive Evidence Weighting (DEW) score — which reflects not 
just the content of the research, but the structural integrity of how it was funded and published.

To put it simply, *if the cost of being wrong is high and the research is funded by unauthenticated or suspicious wallets, the DEW score must be automatically penalized*.

This achieves:
- Openness (no censorship)
- Neutrality (no human judgment)
- Risk-weighted credibility (decisions adapt to ruin exposure)


## Trustless DEW Metadata Fields

Here's the DEW metadata fields to achieve the above.

`ruin_score`	
- Float (0–1) calculated from expected scale × impact. 
- A ruin score simplification would be to have a basic scale from 1 to 3, where 1 (low x low), 2 (low x high or high x low), 3 (high x high).
- Higher score -> more potential for catastrophic error

`funder_anon`
- true/false
- Anonymous funding lowers credibility, especially under high ruin

`funder_wallet_age`
- Age in days
- Young wallets = higher bias risk

`validation_enabled`
- boolean
- Does the research expose raw data, methods, and test logic for external validation?

`refutations`	
- Count of formal, timestamped refutations logged on-chain
- Key signal of fragility or falsification attempts

`replications`
- Count of successful reproductions (with hash-verified code + results)	
- Never definitive proof
- Helps if attached with `test_vectors` and `data_openness`

`version_count`	
- Number of times the research object has been updated or corrected
- Signals ongoing review or instability
- Not required for v1

`data_openness`	
- Measures exposure of datasets/methods for validation
- *none*: No raw data, models, or processing steps are available. Use case: pure summary/paper-only research (e.g., PDF with 
conclusions only).
- *partial*: Some but not all components needed for replication are exposed. Use case: common in commercial or 
privacy-constrained research (e.g., redacted datasets, pseudocode only)
- *full*: All data, methods, preprocessing steps, and test conditions are provided in machine-readable form. Use case: enables 
full replication and adversarial testing.

`test_vectors`	
- boolean
- Are there published test vectors with expected results?


# Reviewing the DEW formula

## Recursive DEW: Why It's Essential 
You're absolutely right that not all replications and refutations are equal. What matters is:

The credibility of a replication or refutation depends on its own DEW. So, to evaluate the credibility of a research object (call it Rn), the DEW algorithm must consider each linked 
replication score (Ti) and each linked refutation score (Fi).

Thus, the DEW scoring function must call itself recursively to walk the tree of evidence.

```
def calculate_dew(research):
    V = compute_local_validation_score(research)
    F = compute_funding_modifier(research) # v1 might start without this (and it's ok)
    R = compute_ruin_multiplier(research)

    local_dew = V * F / R

    replication_effect = 0.0
    for replication in research.replications:
        replication_dew = calculate_dew(replication)
        replication_effect += log2(replication_dew + 1) * 0.05  # dampened growth

    refutation_penalty = 0.0
    for refutation in research.refutations:
        refutation_dew = calculate_dew(refutation)
        refutation_penalty += 0.1 * refutation_dew  # stronger refutations hurt more

    total_dew = max(0, local_dew + replication_effect - refutation_penalty)
    return total_dew


```
