
p.37
> "Hormesis a world coined by pharmacologists is when *a small dose of a harmful substance is actual beneficial for the organism, acting as medicine*."

p.44 p.45 p.46
> "Anti-fragile automatic responses are just a form of redundancy. Nature likes to overinsure itself."

> "Over-compensation is a form of redundancy. A system that overcompensates is necessarily in overshooting mode, building extra capacity and strength in anticipation of a worse outcome and in response to information about the possibility of a hazard."

> "Risk management professionals look in the past for the so called worst-case scenario and use it to estimate future risks-this method is called stress testing. 
> They take the worst historical recession, the worst war, the worst historical move in interest rates, or the worst point in unemployment as an exact estimate for the worst future outcome. But they never noticed the following inconsistency: *this so-called worst case event, when it happened, exceeded the worst case at the time! Well, nature prepares for what has not happened before, assuming worst harm is possible*."

Pag 49
> "Information is anti-fragile it feeds more on attempts to harm it then it does on efforts to promote it."

Pag 57
> "*Errors and their consequences are information*; for small children pain is the only risk management information, as their logical faculties are not very developed. For complex systems are well all about information. This is what we will call __causal opacity__: __it is hard to see the arrow from cause to consequence__, making much of conventional methods of analysis, in addition to standard logic, inapplicable. 
> "The predictability of specific events is low, and it is such opacity that makes it low. Not only that, but because of non-linearities, one needs higher visibility than with regular systems - instead what we have is opacity."

p.65
> "The antifragility of some comes at the expense of the fragility of others."
- in other words, like Taleb says, "what kills me makes others stronger"

> "In a system, the sacrifices of some units - fragile units, that is, or people - are often necessary for the well-being of other units or the whole."

p.66
> "Sadly, the benefits of errors are often conferred on others, the collective - as if individuals were designed to make errors for the greater good, not heir own"
- it's not guaranteed that others will benefit from one's mistakes.
- learning from other's mistakes comes at a cost - the cost of paying attention, understanding what happened and why it happened, and then, somehow, be able to recall these lessons to avoid making the same mistakes.

p.67
> "Unlike with hormesis, the unit does not get stronger in response to stress; it dies. But it accomplishes a transfer of benefits; other units survive - and those units that survive have attributes that imporve the collective of units, leading to modifications commonly assigned the vague term 'evolution'."
> "The most interesting aspect of evolution is that it only works because of its __antifragility__; it's in love with stressors, randomness, uncertainty, and disorder - while individual organisms are relatevely fragile, the gene pool takes advantage of schocks to enhance its fitness."

p.68
> "By leeting organisms go one lifespan at a time, with modificiations between successive generations, nature does not need to predict fugure contitions (...) Every random event will bring its own antidote in the form of ecological variation."

> "Systems subject to randomness - and unpredictability - build a mechanism beyond the robust to opportunistically reinvent themselves each generation, with a continuous change of population and species."


p.418
> "The tragedy is that it is very hard to get funding to replicat - and reject - existing studies. And even if there were money for it, it would be hard to find takers: trying to replicate studies will not make anyone a hero."

p.417
> "There is an optionality on the part of the researcher, no different from that of a banker. The researcher gets the upside, truth gets the downside. The researcher's free option is in *his ability to pick what statistics can confirm his belief - or show a good result - and ditch the rest*. He has the option to stop once he has the __right__ result."
- This is why combining scientific research with capitalism is a dangerous idea.
- Capitalist ventures will sponsor scientific research that confirms that their theory, system or product works.
- They will stop once they found __proof__ that it works (and ignore signs that it doesn't).
- This might be tolerable if the consequences of putting their theory, system or product in practice, only impacts themselves (#skininthegame)
- The problem becomes when the consequences can harm others (ruin scale) and how much harm is going to be inflicted on them (ruin impact)

  
